pid,title,abs,label,h0
63486,Title: Evaluation and Selection of Biases in Machine Learning,"Abstract: In this introduction, we define the term bias as it is used in machine learning systems. We motivate the importance of automated methods for evaluating and selecting biases using a framework of bias selection as search in bias and meta-bias spaces. Recent research in the field of machine learning bias is summarized.",Theory,"Paper 1 addresses case-based learning amidst irrelevant features, introducing the Oblivion algorithm for pruning decision trees and efficiently identifying relevant features, especially in parity concepts. Experimental results in artificial and natural domains support the hypothesis, with discussions on implications, additional work on irrelevant features, and future research directions. Paper 2 introduces the concept of bias in machine learning, emphasizing the need for automated methods to evaluate and select biases. The paper provides a framework for bias selection within bias and meta-bias spaces, summarizing recent research in the field. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Bias in machine learning, Automated bias evaluation, Meta-bias spaces."
2440,"Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In","Abstract: We describe a ranked-model semantics for if-then rules admitting exceptions, which provides a coherent framework for many facets of evidential and causal reasoning. Rule priorities are automatically extracted form the knowledge base to facilitate the construction and retraction of plausible beliefs. To represent causation, the formalism incorporates the principle of Markov shielding which imposes a stratified set of independence constraints on rankings of interpretations. We show how this formalism resolves some classical problems associated with specificity, prediction and abduction, and how it offers a natural way of unifying belief revision, belief update, and reasoning about actions.",Rule_Learning,"Paper 1 addresses case-based learning with irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm efficiently identifies relevant features, especially in parity concepts, as supported by experimental results in artificial and natural domains. The paper discusses implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 presents a ranked-model semantics for if-then rules with exceptions, providing a coherent framework for evidential and causal reasoning. Rule priorities are automatically extracted to facilitate belief construction and retraction. The formalism, incorporating Markov shielding, resolves problems related to specificity, prediction, abduction, and offers a natural unification of belief revision, update, and reasoning about actions. Keywords: Ranked-model semantics, If-then rules, Exceptions, Evidential reasoning, Causal reasoning, Markov shielding, Belief construction, Belief revision, Unified reasoning."
3231,Title: Irrelevant Features and the Subset Selection Problem,"Abstract: We address the problem of finding a subset of features that allows a supervised induction algorithm to induce small high-accuracy concepts. We examine notions of relevance and irrelevance, and show that the definitions used in the machine learning literature do not adequately partition the features into useful categories of relevance. We present definitions for irrelevance and for two degrees of relevance. These definitions improve our understanding of the behavior of previous subset selection algorithms, and help define the subset of features that should be sought. The features selected should depend not only on the features and the target concept, but also on the induction algorithm. We describe a method for feature subset selection using cross-validation that is applicable to any induction algorithm, and discuss experiments conducted with ID3 and C4.5 on artificial and real datasets.",Theory,"Paper 1 addresses case-based learning with irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm efficiently identifies relevant features, especially in parity concepts, as supported by experimental results in artificial and natural domains. The paper discusses implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 focuses on the subset selection problem for supervised induction algorithms, addressing the challenge of finding a subset of features that induces small, high-accuracy concepts. The paper critiques existing notions of relevance and irrelevance in the machine learning literature, proposing improved definitions and degrees of relevance. A feature subset selection method using cross-validation is described, applicable to any induction algorithm, with experiments conducted on artificial and real datasets using ID3 and C4.5. Keywords: Subset selection, Supervised induction algorithms, Relevance, Irrelevance, Cross-validation, Feature selection, ID3, C4.5, Experimental results."
10169,Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features,"Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.",Theory,
954315,Title: Inductive Database Design,"Abstract: When designing a (deductive) database, the designer has to decide for each predicate (or relation) whether it should be defined extensionally or intensionally, and what the definition should look like. An intelligent system is presented to assist the designer in this task. It starts from an example database in which all predicates are defined extensionally. It then tries to compact the database by transforming extensionally defined predicates into intensionally defined ones. The intelligent system employs techniques from the area of inductive logic programming.",Rule_Learning,"Paper 1 addresses case-based learning amidst irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm efficiently identifies relevant features, especially in parity concepts, supported by experimental results in artificial and natural domains. The paper concludes with discussions on experiment implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 discusses the design of deductive databases, focusing on the decision of whether predicates should be defined extensionally or intensionally. An intelligent system is presented to assist designers in transforming extensionally defined predicates into intensionally defined ones, using techniques from inductive logic programming. Keywords: Deductive databases, Extensional definition, Intensional definition, Intelligent system, Inductive logic programming."
144330,Title: Utilizing Prior Concepts for Learning,"Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.",Theory,"Paper 1 addresses the challenge of case-based learning with irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm aims to efficiently identify relevant features, particularly in parity concepts, supported by experimental results in artificial and natural domains. The paper concludes with discussions on experiment implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 focuses on the inductive learning problem, discussing the use of prior concepts to bias the learning method. The transference bias is introduced, and M-FOCL, a Horn clause relational learning algorithm, is presented as a tool that leverages this bias to learn multiple concepts. Preliminary empirical evaluation demonstrates the effects of biasing previous information on both noise-free and noisy data. Keywords: Inductive learning, Prior concepts, Transference bias, M-FOCL algorithm, Horn clause, Relational learning, Multiple concepts, Empirical evaluation, Noise-free data, Noisy data."
56115,Title: Improving Tactical Plans with Genetic Algorithms,Abstract:,Genetic_Algorithms,"Paper 1 addresses the challenge of case-based learning in the presence of irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm aims to efficiently identify relevant features, especially in parity concepts, supported by experimental results in artificial and natural domains. The paper concludes with discussions on experiment implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 focuses on improving tactical plans using genetic algorithms, with the abstract providing limited details. The paper likely explores the application of genetic algorithms to enhance strategic decision-making in tactical planning scenarios. Keywords: Tactical plans, Improvement, Genetic algorithms, Strategic decision-making."
72908,Title: Applications of a logical discovery engine,"Abstract: The clausal discovery engine claudien is presented. claudien discovers regularities in data and is a representative of the inductive logic programming paradigm. As such, it represents data and regularities by means of first order clausal theories. Because the search space of clausal theories is larger than that of attribute value representation, claudien also accepts as input a declarative specification of the language bias, which determines the set of syntactically well-formed regularities. Whereas other papers on claudien focuss on the semantics or logical problem specification of claudien, on the discovery algorithm, or the PAC-learning aspects, this paper wants to illustrate the power of the resulting technique. In order to achieve this aim, we show how claudien can be used to learn 1) integrity constraints in databases, 2) functional dependencies and determinations, 3) properties of sequences, 4) mixed quantitative and qualitative laws, 5) reverse engineering, and 6) classification rules.",Rule_Learning,"Paper 1 addresses the challenge of case-based learning with irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm aims to efficiently identify relevant features, particularly in parity concepts, supported by experimental results in artificial and natural domains. The paper concludes with discussions on experiment implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 presents the clausal discovery engine, claudien, as a representative of the inductive logic programming paradigm. Claudien discovers regularities in data by representing data and regularities through first-order clausal theories. The paper illustrates the versatility of claudien in learning integrity constraints, functional dependencies, properties of sequences, mixed quantitative and qualitative laws, reverse engineering, and classification rules. Keywords: Clausal discovery engine, Inductive logic programming, Regularities, First-order clausal theories, Language bias, Integrity constraints, Functional dependencies, Sequence properties, Reverse engineering, Classification rules."
83461,Title: Dlab: A Declarative Language Bias Formalism,"Abstract: We describe the principles and functionalities of Dlab (Declarative LAnguage Bias). Dlab can be used in inductive learning systems to define syntactically and traverse efficiently finite subspaces of first order clausal logic, be it a set of propositional formulae, association rules, Horn clauses, or full clauses. A Prolog implementation of Dlab is available by ftp access. Keywords: declarative language bias, concept learning, knowledge dis covery",Rule_Learning,"Paper 1 addresses case-based learning with irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm efficiently identifies relevant features, especially in parity concepts, as supported by experimental results in artificial and natural domains. The paper concludes with discussions on experiment implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 presents Dlab, a Declarative Language Bias formalism for use in inductive learning systems. Dlab defines and efficiently traverses finite subspaces of first-order clausal logic, encompassing propositional formulae, association rules, Horn clauses, or full clauses. The abstract mentions a Prolog implementation of Dlab and emphasizes its application in concept learning and knowledge discovery. Keywords: Dlab, Declarative language bias, Inductive learning systems, First-order clausal logic, Propositional formulae, Association rules, Horn clauses, Knowledge discovery."
17811,Title: #1 Robust Feature Selection Algorithms,"Abstract: Selecting a set of features which is optimal for a given task is a problem which plays an important role in a wide variety of contexts including pattern recognition, adaptive control, and machine learning. Our experience with traditional feature selection algorithms in the domain of machine learning lead to an appreciation for their computational efficiency and a concern for their brittleness. This paper describes an alternate approach to feature selection which uses genetic algorithms as the primary search component. Results are presented which suggest that genetic algorithms can be used to increase the robustness of feature selection algorithms without a significant decrease in computational efficiency.",Genetic_Algorithms,"
Paper 1 addresses the challenge of case-based learning with irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm efficiently identifies relevant features, especially in parity concepts, as supported by experimental results in artificial and natural domains. The paper concludes with discussions on experiment implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 focuses on robust feature selection algorithms, highlighting the importance of selecting an optimal set of features in various contexts, including machine learning. The paper introduces an alternate approach using genetic algorithms as the primary search component, aiming to increase the robustness of feature selection algorithms without a significant decrease in computational efficiency. Keywords: Feature selection, Robust algorithms, Genetic algorithms, Pattern recognition, Adaptive control, Machine learning, Computational efficiency."
37483,Title: Learning Approximate Control Rules Of High Utility,"Abstract: One of the difficult problems in the area of explanation based learning is the utility problem; learning too many rules of low utility can lead to swamping, or degradation of performance. This paper introduces two new techniques for improving the utility of learned rules. The first technique is to combine EBL with inductive learning techniques to learn a better set of control rules; the second technique is to use these inductive techniques to learn approximate control rules. The two techniques are synthesized in an algorithm called approximating abductive explanation based learning (AxA-EBL). AxA-EBL is shown to improve substantially over standard EBL in several domains.",Case_Based,"Paper 1 addresses the challenge of case-based learning in the presence of irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees. The algorithm aims to efficiently identify relevant features, particularly in parity concepts, with experimental results supporting its effectiveness in both artificial and natural domains. The paper concludes with discussions on experiment implications, additional work on irrelevant features, and outlines future research directions. Keywords: Case-based learning, Irrelevant features, Oblivion algorithm, Decision trees, Parity concepts, Experimental results, Natural domains, Future research.

Paper 2 focuses on the utility problem in explanation-based learning, introducing two techniques to improve the utility of learned rules. The first technique combines Explanation-Based Learning (EBL) with inductive learning techniques to enhance the set of control rules. The second technique involves using inductive techniques to learn approximate control rules. The resulting algorithm, called Approximating Abductive Explanation Based Learning (AxA-EBL), demonstrates substantial improvement over standard EBL in various domains. Keywords: Explanation-based learning, Utility problem, Control rules, Inductive learning, Approximate control rules, AxA-EBL algorithm, Swamping, Performance degradation, Learning techniques."
