{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pair representations $h_v^{(0)}$  赋值子图中每个节点和源节点信息\n",
    "2. Message $M_v^{(1)}$: {$h_v^{(0)}$, 所有指向v的节点x的$h_x$和(x, v)总结后的信息}\n",
    "3. 总结所有Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample.csv')\n",
    "cite = pd.read_csv('sample_cite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_pid</th>\n",
       "      <th>src_title</th>\n",
       "      <th>src_abs</th>\n",
       "      <th>src_label</th>\n",
       "      <th>v_pid</th>\n",
       "      <th>v_title</th>\n",
       "      <th>v_abs</th>\n",
       "      <th>v_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>63486</td>\n",
       "      <td>Title: Evaluation and Selection of Biases in M...</td>\n",
       "      <td>Abstract: In this introduction, we define the ...</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>2440</td>\n",
       "      <td>Title: Quinlan, 1990 J.R. Quinlan. Learning lo...</td>\n",
       "      <td>Abstract: We describe a ranked-model semantics...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>3231</td>\n",
       "      <td>Title: Irrelevant Features and the Subset Sele...</td>\n",
       "      <td>Abstract: We address the problem of finding a ...</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>954315</td>\n",
       "      <td>Title: Inductive Database Design</td>\n",
       "      <td>Abstract: When designing a (deductive) databas...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>144330</td>\n",
       "      <td>Title: Utilizing Prior Concepts for Learning</td>\n",
       "      <td>Abstract: The inductive learning problem consi...</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>56115</td>\n",
       "      <td>Title: Improving Tactical Plans with Genetic A...</td>\n",
       "      <td>Abstract:</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>72908</td>\n",
       "      <td>Title: Applications of a logical discovery engine</td>\n",
       "      <td>Abstract: The clausal discovery engine claudie...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>83461</td>\n",
       "      <td>Title: Dlab: A Declarative Language Bias Forma...</td>\n",
       "      <td>Abstract: We describe the principles and funct...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>17811</td>\n",
       "      <td>Title: #1 Robust Feature Selection Algorithms</td>\n",
       "      <td>Abstract: Selecting a set of features which is...</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>37483</td>\n",
       "      <td>Title: Learning Approximate Control Rules Of H...</td>\n",
       "      <td>Abstract: One of the difficult problems in the...</td>\n",
       "      <td>Case_Based</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_pid                                          src_title  \\\n",
       "0    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "1    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "2    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "3    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "4    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "5    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "6    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "7    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "8    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "9    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "\n",
       "                                             src_abs src_label   v_pid  \\\n",
       "0  Abstract: In this paper, we address the proble...    Theory   63486   \n",
       "1  Abstract: In this paper, we address the proble...    Theory    2440   \n",
       "2  Abstract: In this paper, we address the proble...    Theory    3231   \n",
       "3  Abstract: In this paper, we address the proble...    Theory  954315   \n",
       "4  Abstract: In this paper, we address the proble...    Theory  144330   \n",
       "5  Abstract: In this paper, we address the proble...    Theory   56115   \n",
       "6  Abstract: In this paper, we address the proble...    Theory   72908   \n",
       "7  Abstract: In this paper, we address the proble...    Theory   83461   \n",
       "8  Abstract: In this paper, we address the proble...    Theory   17811   \n",
       "9  Abstract: In this paper, we address the proble...    Theory   37483   \n",
       "\n",
       "                                             v_title  \\\n",
       "0  Title: Evaluation and Selection of Biases in M...   \n",
       "1  Title: Quinlan, 1990 J.R. Quinlan. Learning lo...   \n",
       "2  Title: Irrelevant Features and the Subset Sele...   \n",
       "3                   Title: Inductive Database Design   \n",
       "4       Title: Utilizing Prior Concepts for Learning   \n",
       "5  Title: Improving Tactical Plans with Genetic A...   \n",
       "6  Title: Applications of a logical discovery engine   \n",
       "7  Title: Dlab: A Declarative Language Bias Forma...   \n",
       "8      Title: #1 Robust Feature Selection Algorithms   \n",
       "9  Title: Learning Approximate Control Rules Of H...   \n",
       "\n",
       "                                               v_abs             v_label  \n",
       "0  Abstract: In this introduction, we define the ...              Theory  \n",
       "1  Abstract: We describe a ranked-model semantics...       Rule_Learning  \n",
       "2  Abstract: We address the problem of finding a ...              Theory  \n",
       "3  Abstract: When designing a (deductive) databas...       Rule_Learning  \n",
       "4  Abstract: The inductive learning problem consi...              Theory  \n",
       "5                                          Abstract:  Genetic_Algorithms  \n",
       "6  Abstract: The clausal discovery engine claudie...       Rule_Learning  \n",
       "7  Abstract: We describe the principles and funct...       Rule_Learning  \n",
       "8  Abstract: Selecting a set of features which is...  Genetic_Algorithms  \n",
       "9  Abstract: One of the difficult problems in the...          Case_Based  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一步\n",
    "src = sample[sample.pid == 10169]\n",
    "tar = sample[sample.pid == 63486]\n",
    "v_df = sample[sample.pid != src.pid.values[0]].reset_index(drop=True)\n",
    "\n",
    "h_v = pd.DataFrame({\n",
    "    'src_pid': [src.pid.values[0]] * len(v_df),\n",
    "    'src_title': [src.title.values[0]] * len(v_df),\n",
    "    'src_abs': [src['abs'].values[0]] * len(v_df),\n",
    "    'src_label': [src.label.values[0]] * len(v_df),\n",
    "    'v_pid': v_df.pid,\n",
    "    'v_title': v_df.title,\n",
    "    'v_abs': v_df['abs'],\n",
    "    'v_label': v_df.label\n",
    "})\n",
    "h_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3    10169\n",
       " Name: pid, dtype: int64,\n",
       " 63486)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.pid, tar['pid'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator\n",
    "\n",
    "hv_list_orig = []\n",
    "for i in range(len(h_v)):\n",
    "\n",
    "    src_title, src_abs, src_label = h_v.loc[i, 'src_title'], h_v.loc[i, 'src_abs'], h_v.loc[i, 'src_label']\n",
    "    tar_pid, tar_title, tar_abs, tar_label = h_v.loc[i, 'v_pid'], h_v.loc[i, 'v_title'], h_v.loc[i, 'v_abs'], h_v.loc[i, 'v_label']\n",
    "\n",
    "    # if tar['pid'].values[0] == tar_pid:\n",
    "    #     continue\n",
    "    \n",
    "    # print(tar_pid)\n",
    "\n",
    "    Indicator_prompt = f\"\"\"\n",
    "Given information of a source paper and a target paper shown as follow:\n",
    "source paper:\n",
    "title:{src_title}\n",
    "abstract:{src_abs}\n",
    "label:{src_label}\n",
    "target paper:\n",
    "title:{tar_title}\n",
    "abstract:{tar_abs}\n",
    "label:{tar_label}\n",
    "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
    "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
    "\"\"\"\n",
    "\n",
    "    hv_list_orig.append(Indicator_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Evaluation and Selection of Biases in Machine Learning\n",
      "abstract:Abstract: In this introduction, we define the term bias as it is used in machine learning systems. We motivate the importance of automated methods for evaluating and selecting biases using a framework of bias selection as search in bias and meta-bias spaces. Recent research in the field of machine learning bias is summarized.\n",
      "label:Theory\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\n",
      "abstract:Abstract: We describe a ranked-model semantics for if-then rules admitting exceptions, which provides a coherent framework for many facets of evidential and causal reasoning. Rule priorities are automatically extracted form the knowledge base to facilitate the construction and retraction of plausible beliefs. To represent causation, the formalism incorporates the principle of Markov shielding which imposes a stratified set of independence constraints on rankings of interpretations. We show how this formalism resolves some classical problems associated with specificity, prediction and abduction, and how it offers a natural way of unifying belief revision, belief update, and reasoning about actions.\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Irrelevant Features and the Subset Selection Problem\n",
      "abstract:Abstract: We address the problem of finding a subset of features that allows a supervised induction algorithm to induce small high-accuracy concepts. We examine notions of relevance and irrelevance, and show that the definitions used in the machine learning literature do not adequately partition the features into useful categories of relevance. We present definitions for irrelevance and for two degrees of relevance. These definitions improve our understanding of the behavior of previous subset selection algorithms, and help define the subset of features that should be sought. The features selected should depend not only on the features and the target concept, but also on the induction algorithm. We describe a method for feature subset selection using cross-validation that is applicable to any induction algorithm, and discuss experiments conducted with ID3 and C4.5 on artificial and real datasets.\n",
      "label:Theory\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Inductive Database Design\n",
      "abstract:Abstract: When designing a (deductive) database, the designer has to decide for each predicate (or relation) whether it should be defined extensionally or intensionally, and what the definition should look like. An intelligent system is presented to assist the designer in this task. It starts from an example database in which all predicates are defined extensionally. It then tries to compact the database by transforming extensionally defined predicates into intensionally defined ones. The intelligent system employs techniques from the area of inductive logic programming.\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Improving Tactical Plans with Genetic Algorithms\n",
      "abstract:Abstract:\n",
      "label:Genetic_Algorithms\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Applications of a logical discovery engine\n",
      "abstract:Abstract: The clausal discovery engine claudien is presented. claudien discovers regularities in data and is a representative of the inductive logic programming paradigm. As such, it represents data and regularities by means of first order clausal theories. Because the search space of clausal theories is larger than that of attribute value representation, claudien also accepts as input a declarative specification of the language bias, which determines the set of syntactically well-formed regularities. Whereas other papers on claudien focuss on the semantics or logical problem specification of claudien, on the discovery algorithm, or the PAC-learning aspects, this paper wants to illustrate the power of the resulting technique. In order to achieve this aim, we show how claudien can be used to learn 1) integrity constraints in databases, 2) functional dependencies and determinations, 3) properties of sequences, 4) mixed quantitative and qualitative laws, 5) reverse engineering, and 6) classification rules.\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Dlab: A Declarative Language Bias Formalism\n",
      "abstract:Abstract: We describe the principles and functionalities of Dlab (Declarative LAnguage Bias). Dlab can be used in inductive learning systems to define syntactically and traverse efficiently finite subspaces of first order clausal logic, be it a set of propositional formulae, association rules, Horn clauses, or full clauses. A Prolog implementation of Dlab is available by ftp access. Keywords: declarative language bias, concept learning, knowledge dis covery\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: #1 Robust Feature Selection Algorithms\n",
      "abstract:Abstract: Selecting a set of features which is optimal for a given task is a problem which plays an important role in a wide variety of contexts including pattern recognition, adaptive control, and machine learning. Our experience with traditional feature selection algorithms in the domain of machine learning lead to an appreciation for their computational efficiency and a concern for their brittleness. This paper describes an alternate approach to feature selection which uses genetic algorithms as the primary search component. Results are presented which suggest that genetic algorithms can be used to increase the robustness of feature selection algorithms without a significant decrease in computational efficiency.\n",
      "label:Genetic_Algorithms\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Learning Approximate Control Rules Of High Utility\n",
      "abstract:Abstract: One of the difficult problems in the area of explanation based learning is the utility problem; learning too many rules of low utility can lead to swamping, or degradation of performance. This paper introduces two new techniques for improving the utility of learned rules. The first technique is to combine EBL with inductive learning techniques to learn a better set of control rules; the second technique is to use these inductive techniques to learn approximate control rules. The two techniques are synthesized in an algorithm called approximating abductive explanation based learning (AxA-EBL). AxA-EBL is shown to improve substantially over standard EBL in several domains.\n",
      "label:Case_Based\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "for hv in hv_list_orig:\n",
    "    print(hv)\n",
    "    print('======================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2440 72908\n",
      "paper1:\n",
      "title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\n",
      "label:Rule_Learning\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Applications of a logical discovery engine\n",
      "label:Rule_Learning\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "3231 63486\n",
      "paper1:\n",
      "title:Title: Irrelevant Features and the Subset Selection Problem\n",
      "label:Theory\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Evaluation and Selection of Biases in Machine Learning\n",
      "label:Theory\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "10169 3231\n",
      "paper1:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "label:Theory\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Irrelevant Features and the Subset Selection Problem\n",
      "label:Theory\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "17811 63486\n",
      "paper1:\n",
      "title:Title: #1 Robust Feature Selection Algorithms\n",
      "label:Genetic_Algorithms\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Evaluation and Selection of Biases in Machine Learning\n",
      "label:Theory\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "37483 2440\n",
      "paper1:\n",
      "title:Title: Learning Approximate Control Rules Of High Utility\n",
      "label:Case_Based\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\n",
      "label:Rule_Learning\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "56115 63486\n",
      "paper1:\n",
      "title:Title: Improving Tactical Plans with Genetic Algorithms\n",
      "label:Genetic_Algorithms\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Evaluation and Selection of Biases in Machine Learning\n",
      "label:Theory\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "63486 83461\n",
      "paper1:\n",
      "title:Title: Evaluation and Selection of Biases in Machine Learning\n",
      "label:Theory\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Dlab: A Declarative Language Bias Formalism\n",
      "label:Rule_Learning\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "72908 954315\n",
      "paper1:\n",
      "title:Title: Applications of a logical discovery engine\n",
      "label:Rule_Learning\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Inductive Database Design\n",
      "label:Rule_Learning\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "83461 954315\n",
      "paper1:\n",
      "title:Title: Dlab: A Declarative Language Bias Formalism\n",
      "label:Rule_Learning\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Inductive Database Design\n",
      "label:Rule_Learning\n",
      "    \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "144330 63486\n",
      "paper1:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "label:Theory\n",
      "cites\n",
      "paper2:\n",
      "title:Title: Evaluation and Selection of Biases in Machine Learning\n",
      "label:Theory\n",
      "    \n",
      "\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# w(x, r, v)\n",
    "# cite, src, tar\n",
    "w_list_orig = []\n",
    "for i in range(len(cite)):\n",
    "    src_id, tar_id = cite.loc[i, 'src_id'], cite.loc[i, 'tar_id']\n",
    "\n",
    "    if src.pid.values[0] == src_id and tar.pid.values[0] == tar_id:\n",
    "        # print(src_id, tar_id)\n",
    "        continue\n",
    "    \n",
    "    src_title, src_abs, src_label = sample[sample.pid == src_id].title.values[0], sample[sample.pid == src_id]['abs'].values[0], sample[sample.pid == src_id].label.values[0]\n",
    "    tar_title, tar_abs, tar_label = sample[sample.pid == tar_id].title.values[0], sample[sample.pid == tar_id]['abs'].values[0], sample[sample.pid == tar_id].label.values[0]\n",
    "    \n",
    "\n",
    "    w_prompt = f\"\"\"\n",
    "{src_id} {tar_id}\n",
    "paper1:\n",
    "title:{src_title}\n",
    "label:{src_label}\n",
    "cites\n",
    "paper2:\n",
    "title:{tar_title}\n",
    "label:{tar_label}\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "    w_list_orig.append(w_prompt)\n",
    "\n",
    "for w in w_list_orig:\n",
    "    print(w)\n",
    "    print('=========================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{63486: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" explores addressing case-based learning amidst irrelevant features, proposing the Oblivion algorithm for efficient feature identification, especially with interacting features like parity concepts. It discusses experimental results in artificial domains supporting its hypothesis, noting varied outcomes in natural domains, concluding with considerations for future research. The target paper, \"Evaluation and Selection of Biases in Machine Learning,\" introduces and defines biases in machine learning, emphasizing the significance of automated methods for bias evaluation and selection through frameworks of bias/meta-bias spaces, summarizing recent research in this area.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results\\rTarget paper: Machine learning biases, Bias evaluation, Bias selection, Meta-bias spaces, Automated methods, Research summary'],\n",
       "  'w': ['paper1:title:Title: Irrelevant Features and the Subset Selection Problemlabel:Theorycitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory',\n",
       "   'paper1:title:Title: #1 Robust Feature Selection Algorithmslabel:Genetic_Algorithmscitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory',\n",
       "   'paper1:title:Title: Improving Tactical Plans with Genetic Algorithmslabel:Genetic_Algorithmscitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory',\n",
       "   'paper1:title:Title: Utilizing Prior Concepts for Learninglabel:Theorycitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory']},\n",
       " 2440: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" addresses case-based learning amid irrelevant features, proposing the Oblivion algorithm for feature identification, particularly in interacting scenarios like parity concepts. It discusses experimental results and implications for future research. The target paper, \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations,\" introduces a ranked-model semantics for if-then rules, facilitating evidential and causal reasoning by extracting rule priorities automatically. It resolves problems related to specificity, prediction, abduction, and unifies belief revision, update, and reasoning about actions.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Ranked-model semantics, If-then rules, Evidential reasoning, Causal reasoning, Rule priorities, Markov shielding, Belief revision, Abduction, Belief update, Reasoning about actions'],\n",
       "  'w': ['paper1:title:Title: Learning Approximate Control Rules Of High Utilitylabel:Case_Basedcitespaper2:title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. Inlabel:Rule_Learning']},\n",
       " 3231: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning amidst irrelevant features, focusing on feature identification even in interacting scenarios like parity concepts. It reports experimental outcomes and outlines future research implications. The target paper, \"Irrelevant Features and the Subset Selection Problem,\" addresses the challenge of identifying feature subsets conducive to small, high-accuracy concepts in supervised induction algorithms. It refines notions of relevance, presents degrees of relevance, proposes a method for feature subset selection using cross-validation applicable to various induction algorithms, and discusses experiments with ID3 and C4.5 on artificial and real datasets.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Subset selection, Supervised induction algorithms, Relevance, Irrelevance, Feature subset, Cross-validation, ID3, C4.5, Artificial datasets, Real datasets'],\n",
       "  'w': ['paper1:title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Featureslabel:Theorycitespaper2:title:Title: Irrelevant Features and the Subset Selection Problemlabel:Theory']},\n",
       " 954315: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" focuses on case-based learning amidst irrelevant features, introducing the Oblivion algorithm for effective feature identification, particularly in scenarios involving interacting features like parity concepts. It reports experimental results and outlines future research directions regarding irrelevant features. The target paper, \"Inductive Database Design,\" presents an intelligent system assisting in the design of deductive databases by transforming extensionally defined predicates into intensionally defined ones using techniques from inductive logic programming.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Inductive database design, Deductive databases, Extensional predicates, Intensional predicates, Intelligent system, Inductive logic programming, Database transformation\\r\\r\\r\\r\\r\\r'],\n",
       "  'w': ['paper1:title:Title: Applications of a logical discovery enginelabel:Rule_Learningcitespaper2:title:Title: Inductive Database Designlabel:Rule_Learning',\n",
       "   'paper1:title:Title: Dlab: A Declarative Language Bias Formalismlabel:Rule_Learningcitespaper2:title:Title: Inductive Database Designlabel:Rule_Learning']},\n",
       " 144330: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning amid irrelevant features, emphasizing feature identification even in scenarios involving interacting features like parity concepts. It reports experimental findings and discusses future research directions on irrelevant features. The target paper, \"Utilizing Prior Concepts for Learning,\" explores biasing learning methods to leverage previously learned concepts in the same domain, introducing a transference bias and M-FOCL, a Horn clause relational learning algorithm, to utilize this bias for learning multiple concepts. It provides preliminary empirical evaluation showcasing the impact of biasing previous information on both noise-free and noisy data.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Inductive learning, Biasing learning methods, Prior concepts utilization, Transference bias, M-FOCL algorithm, Horn clause, Relational learning, Multiple concepts, Empirical evaluation, Noise-free data, Noisy data'],\n",
       "  'w': []},\n",
       " 56115: {'h': [' The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" addresses case-based learning amidst irrelevant features, introducing the Oblivion algorithm for efficient feature identification, especially in scenarios with interacting features like parity concepts. It presents experimental results and discusses future research implications regarding irrelevant features. The target paper, \"Improving Tactical Plans with Genetic Algorithms,\" lacks provided information in the abstract to summarize its content or relevance to the source paper.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Genetic algorithms, Tactical plans'],\n",
       "  'w': []},\n",
       " 72908: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning with irrelevant features, focusing on feature identification even when features interact, like in parity concepts. It reports experimental outcomes and discusses future research directions regarding irrelevant features. The target paper, \"Applications of a logical discovery engine,\" introduces the clausal discovery engine claudien, emphasizing its ability to discover regularities in data using inductive logic programming. It showcases claudien\\'s applications in learning integrity constraints, functional dependencies, properties of sequences, mixed quantitative and qualitative laws, reverse engineering, and classification rules.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Claudien, Logical discovery engine, Regularities in data, Inductive logic programming, Integrity constraints, Functional dependencies, Sequences, Mixed quantitative and qualitative laws, Reverse engineering, Classification rules'],\n",
       "  'w': ['paper1:title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. Inlabel:Rule_Learningcitespaper2:title:Title: Applications of a logical discovery enginelabel:Rule_Learning']},\n",
       " 83461: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning with irrelevant features, emphasizing feature identification even when they interact, like in parity concepts. It presents experimental outcomes and outlines future research directions regarding irrelevant features. The target paper, \"Dlab: A Declarative Language Bias Formalism,\" details Dlab\\'s functionalities for defining and efficiently traversing finite subspaces of first-order clausal logic in inductive learning systems. It focuses on syntactical definition, Prolog implementation, and applications in concept learning and knowledge discovery.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Dlab, Declarative language bias, Inductive learning systems, First-order clausal logic, Syntactical definition, Prolog implementation, Concept learning, Knowledge discovery'],\n",
       "  'w': ['paper1:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theorycitespaper2:title:Title: Dlab: A Declarative Language Bias Formalismlabel:Rule_Learning']},\n",
       " 17811: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning with irrelevant features, emphasizing efficient feature identification, especially in scenarios involving interacting features like parity concepts. It reports experimental findings and discusses future research directions regarding irrelevant features. The target paper, \"#1 Robust Feature Selection Algorithms,\" discusses the importance of feature selection in various contexts, highlighting the brittleness of traditional algorithms and proposing an alternate approach using genetic algorithms to enhance robustness without sacrificing computational efficiency.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Feature selection, Genetic algorithms, Robustness, Computational efficiency, Pattern recognition, Adaptive control, Machine learning, Brittleness'],\n",
       "  'w': []},\n",
       " 37483: {'h': ['The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" presents the Oblivion algorithm for case-based learning amidst irrelevant features, focusing on efficient feature identification, particularly in scenarios involving interacting features like parity concepts. It reports experimental results and discusses future research directions related to irrelevant features. The target paper, \"Learning Approximate Control Rules Of High Utility,\" addresses the utility problem in explanation-based learning, introducing techniques to improve rule utility by combining EBL with inductive learning and learning approximate control rules through AxA-EBL, showcasing substantial improvements over standard EBL in various domains.\\r\\rKeywords:\\rSource paper: Case-based learning, Irrelevant features, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implications\\rTarget paper: Explanation-based learning, Rule utility, Inductive learning, Approximate control rules, AxA-EBL algorithm, Utility problem, Performance improvement, Domains'],\n",
       "  'w': []}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# message\n",
    "\n",
    "src_id = src.pid.values[0]\n",
    "tar_id = tar.pid.values[0]\n",
    "\n",
    "message = {}\n",
    "for i in range(len(sample)):\n",
    "\n",
    "    node_id = sample.loc[i, 'pid']\n",
    "\n",
    "    if node_id == src_id:\n",
    "        continue\n",
    "\n",
    "\n",
    "    h0 = sample.loc[i, 'h0']\n",
    "    message[node_id] = {'h': [h0.replace('\\n', '')]}\n",
    "\n",
    "message\n",
    "\n",
    "w\n",
    "for key in message.keys():\n",
    "    x_df = cite[cite.tar_id == key].reset_index(drop = True)\n",
    "    message[key]['w'] = []\n",
    "    for i in range(len(x_df)):\n",
    "        if x_df.loc[i, 'src_id'] == src_id and x_df.loc[i, 'tar_id'] == tar_id:\n",
    "            continue\n",
    "\n",
    "        message[key]['w'].append(x_df.loc[i, 'w'].replace('\\r', '').replace('\\n', ''))\n",
    "\n",
    "\n",
    "message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63486\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Machine learning biases, Bias evaluation, Bias selection, Meta-bias spaces, Automated methods, Research summaryntal results irrelevant features, proposing the Oblivion algorithm for efficient feature identification, especially with interacting features like parity concepts. It discusses experimental results in artificial domains supporting its hypothesis, noting varied outcomes in natural domains, concluding with considerations for future research. The target paper, \"Evaluation and Selection of Biases in Machine Learning,\" introduces and defines biases in machine learning, emphasizing the significance of automated methods for bias evaluation and selection through frameworks of bias/meta-bias spaces, summarizing recent research in this area.\n",
      "the information about the paper cite the target paper:\n",
      "1. paper1:title:Title: Irrelevant Features and the Subset Selection Problemlabel:Theorycitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory \n",
      "2. paper1:title:Title: #1 Robust Feature Selection Algorithmslabel:Genetic_Algorithmscitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory \n",
      "3. paper1:title:Title: Improving Tactical Plans with Genetic Algorithmslabel:Genetic_Algorithmscitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory \n",
      "4. paper1:title:Title: Utilizing Prior Concepts for Learninglabel:Theorycitespaper2:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theory \n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "2440\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Ranked-model semantics, If-then rules, Evidential reasoning, Causal reasoning, Rule priorities, Markov shielding, Belief revision, Abduction, Belief update, Reasoning about actionsentification, particularly in interacting scenarios like parity concepts. It discusses experimental results and implications for future research. The target paper, \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations,\" introduces a ranked-model semantics for if-then rules, facilitating evidential and causal reasoning by extracting rule priorities automatically. It resolves problems related to specificity, prediction, abduction, and unifies belief revision, update, and reasoning about actions.\n",
      "the information about the paper cite the target paper:\n",
      "1. paper1:title:Title: Learning Approximate Control Rules Of High Utilitylabel:Case_Basedcitespaper2:title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. Inlabel:Rule_Learning \n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "3231\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Subset selection, Supervised induction algorithms, Relevance, Irrelevance, Feature subset, Cross-validation, ID3, C4.5, Artificial datasets, Real datasetseatures, focusing on feature identification even in interacting scenarios like parity concepts. It reports experimental outcomes and outlines future research implications. The target paper, \"Irrelevant Features and the Subset Selection Problem,\" addresses the challenge of identifying feature subsets conducive to small, high-accuracy concepts in supervised induction algorithms. It refines notions of relevance, presents degrees of relevance, proposes a method for feature subset selection using cross-validation applicable to various induction algorithms, and discusses experiments with ID3 and C4.5 on artificial and real datasets.\n",
      "the information about the paper cite the target paper:\n",
      "1. paper1:title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Featureslabel:Theorycitespaper2:title:Title: Irrelevant Features and the Subset Selection Problemlabel:Theory \n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "954315\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Inductive database design, Deductive databases, Extensional predicates, Intensional predicates, Intelligent system, Inductive logic programming, Database transformationhm for effective feature identification, particularly in scenarios involving interacting features like parity concepts. It reports experimental results and outlines future research directions regarding irrelevant features. The target paper, \"Inductive Database Design,\" presents an intelligent system assisting in the design of deductive databases by transforming extensionally defined predicates into intensionally defined ones using techniques from inductive logic programming.\n",
      "the information about the paper cite the target paper:\n",
      "1. paper1:title:Title: Applications of a logical discovery enginelabel:Rule_Learningcitespaper2:title:Title: Inductive Database Designlabel:Rule_Learning \n",
      "2. paper1:title:Title: Dlab: A Declarative Language Bias Formalismlabel:Rule_Learningcitespaper2:title:Title: Inductive Database Designlabel:Rule_Learning \n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "144330\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Inductive learning, Biasing learning methods, Prior concepts utilization, Transference bias, M-FOCL algorithm, Horn clause, Relational learning, Multiple concepts, Empirical evaluation, Noise-free data, Noisy data involving interacting features like parity concepts. It reports experimental findings and discusses future research directions on irrelevant features. The target paper, \"Utilizing Prior Concepts for Learning,\" explores biasing learning methods to leverage previously learned concepts in the same domain, introducing a transference bias and M-FOCL, a Horn clause relational learning algorithm, to utilize this bias for learning multiple concepts. It provides preliminary empirical evaluation showcasing the impact of biasing previous information on both noise-free and noisy data.\n",
      "the information about the paper cite the target paper:\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "56115\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Genetic algorithms, Tactical plansatures, Oblivion algorithm, Feature identification, Parity concepts, Experimental results, Future research implicationsblivion algorithm for efficient feature identification, especially in scenarios with interacting features like parity concepts. It presents experimental results and discusses future research implications regarding irrelevant features. The target paper, \"Improving Tactical Plans with Genetic Algorithms,\" lacks provided information in the abstract to summarize its content or relevance to the source paper.\n",
      "the information about the paper cite the target paper:\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "72908\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Claudien, Logical discovery engine, Regularities in data, Inductive logic programming, Integrity constraints, Functional dependencies, Sequences, Mixed quantitative and qualitative laws, Reverse engineering, Classification rulese in parity concepts. It reports experimental outcomes and discusses future research directions regarding irrelevant features. The target paper, \"Applications of a logical discovery engine,\" introduces the clausal discovery engine claudien, emphasizing its ability to discover regularities in data using inductive logic programming. It showcases claudien's applications in learning integrity constraints, functional dependencies, properties of sequences, mixed quantitative and qualitative laws, reverse engineering, and classification rules.\n",
      "the information about the paper cite the target paper:\n",
      "1. paper1:title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. Inlabel:Rule_Learningcitespaper2:title:Title: Applications of a logical discovery enginelabel:Rule_Learning \n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "83461\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Dlab, Declarative language bias, Inductive learning systems, First-order clausal logic, Syntactical definition, Prolog implementation, Concept learning, Knowledge discovery feature identification even when they interact, like in parity concepts. It presents experimental outcomes and outlines future research directions regarding irrelevant features. The target paper, \"Dlab: A Declarative Language Bias Formalism,\" details Dlab's functionalities for defining and efficiently traversing finite subspaces of first-order clausal logic in inductive learning systems. It focuses on syntactical definition, Prolog implementation, and applications in concept learning and knowledge discovery.\n",
      "the information about the paper cite the target paper:\n",
      "1. paper1:title:Title: Evaluation and Selection of Biases in Machine Learninglabel:Theorycitespaper2:title:Title: Dlab: A Declarative Language Bias Formalismlabel:Rule_Learning \n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "17811\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Feature selection, Genetic algorithms, Robustness, Computational efficiency, Pattern recognition, Adaptive control, Machine learning, Brittlenessicationsatures, emphasizing efficient feature identification, especially in scenarios involving interacting features like parity concepts. It reports experimental findings and discusses future research directions regarding irrelevant features. The target paper, \"#1 Robust Feature Selection Algorithms,\" discusses the importance of feature selection in various contexts, highlighting the brittleness of traditional algorithms and proposing an alternate approach using genetic algorithms to enhance robustness without sacrificing computational efficiency.\n",
      "the information about the paper cite the target paper:\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n",
      "37483\n",
      "\n",
      "Given the source and target papers, and information about the papers that cite the target paper:\n",
      "source and target information:\n",
      "Target paper: Explanation-based learning, Rule utility, Inductive learning, Approximate control rules, AxA-EBL algorithm, Utility problem, Performance improvement, Domainses, focusing on efficient feature identification, particularly in scenarios involving interacting features like parity concepts. It reports experimental results and discusses future research directions related to irrelevant features. The target paper, \"Learning Approximate Control Rules Of High Utility,\" addresses the utility problem in explanation-based learning, introducing techniques to improve rule utility by combining EBL with inductive learning and learning approximate control rules through AxA-EBL, showcasing substantial improvements over standard EBL in various domains.\n",
      "the information about the paper cite the target paper:\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for key in message.keys():\n",
    "    h, cite_list = message[key]['h'][0], message[key]['w']\n",
    "\n",
    "    cite_str = \"\"\n",
    "\n",
    "    for i, w in enumerate(cite_list):\n",
    "        cite_str += f\"{i+1}. {w} \\n\"\n",
    "\n",
    "    agg_prompt = f\"\"\"\n",
    "Given the source and target papers, and information about the papers that cite the target paper:\n",
    "source and target information:\n",
    "{h}\n",
    "the information about the paper cite the target paper:\n",
    "{cite_str}\n",
    "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
    "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
    "\"\"\"\n",
    "    print(key)\n",
    "    print(agg_prompt)\n",
    "\n",
    "    print('============================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10169 63486\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" delves into case-based learning amid irrelevant features, introducing the Oblivion algorithm for efficient feature identification, particularly in scenarios involving interacting features like parity concepts. It presents experimental results supporting its thesis in artificial domains but highlights varying outcomes in natural domains and suggests avenues for future investigation. The target paper, \"Evaluation and Selection of Biases in Machine Learning,\" defines biases in machine learning, emphasizing automated bias evaluation and selection using bias/meta-bias spaces, summarizing recent advancements in this domain. It has been cited by papers focusing on subset selection problems, robust feature selection algorithms, tactical plans enhancement with genetic algorithms, and leveraging prior concepts for learning.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Keywords for the target paper:\n",
      "\n",
      "Machine learning biases\n",
      "Bias evaluation\n",
      "Bias selection\n",
      "Meta-bias spaces\n",
      "Automated methods\n",
      "Research summary\n",
      "Subset selection problems\n",
      "Robust feature selection algorithms\n",
      "Tactical plans enhancement\n",
      "Genetic algorithms\n",
      "Prior concepts for learning\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Evaluation and Selection of Biases in Machine Learning\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 2440\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" focuses on case-based learning amidst irrelevant features, proposing the Oblivion algorithm for feature identification, especially in scenarios involving interacting concepts like parity. It discusses experimental findings and implications for future research. The target paper, \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations,\" introduces ranked-model semantics for if-then rules, aiding evidential and causal reasoning through automatic extraction of rule priorities, resolving issues related to specificity, prediction, abduction, and unifying belief revision and reasoning about actions. It has been cited by a paper discussing learning approximate control rules with high utility in a case-based context.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Ranked-model semantics\n",
      "If-then rules\n",
      "Evidential reasoning\n",
      "Causal reasoning\n",
      "Rule priorities\n",
      "Markov shielding\n",
      "Belief revision\n",
      "Abduction\n",
      "Belief update\n",
      "Reasoning about actions\n",
      "First-order theory revision\n",
      "Machine learning\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 3231\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning amidst irrelevant features, emphasizing feature identification even within interacting scenarios like parity concepts. It reports experimental findings and highlights future research directions. The target paper, \"Irrelevant Features and the Subset Selection Problem,\" addresses feature subset selection challenges in supervised induction algorithms by refining relevance notions, proposing a cross-validation-based method applicable to various algorithms like ID3 and C4.5, and discusses experiments on both artificial and real datasets. The source paper citing the target paper emphasizes the theoretical aspects of learning amidst irrelevant features.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Theoretical aspects\n",
      "Keywords for the target paper:\n",
      "\n",
      "Subset selection\n",
      "Supervised induction algorithms\n",
      "Relevance\n",
      "Irrelevance\n",
      "Feature subset\n",
      "Cross-validation\n",
      "ID3\n",
      "C4.5\n",
      "Artificial datasets\n",
      "Real datasets\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Irrelevant Features and the Subset Selection Problem\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 954315\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for effective feature identification in case-based learning scenarios involving interacting features like parity concepts. It discusses experimental findings and future research directions concerning irrelevant features. The target paper, \"Inductive Database Design,\" presents an intelligent system for aiding deductive database design through transforming extensionally defined predicates into intensionally defined ones using techniques from inductive logic programming. Papers citing the target paper explore applications of a logical discovery engine and a declarative language bias formalism within the realm of rule learning.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Inductive database design\n",
      "Deductive databases\n",
      "Extensional predicates\n",
      "Intensional predicates\n",
      "Intelligent system\n",
      "Inductive logic programming\n",
      "Database transformation\n",
      "Logical discovery engine\n",
      "Declarative language bias formalism\n",
      "Rule learning\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Inductive Database Design\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 144330\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning amidst irrelevant features and explores future research directions in this context. The target paper, \"Utilizing Prior Concepts for Learning,\" focuses on biasing learning methods using previously learned concepts, introducing a transference bias and the M-FOCL algorithm for relational learning. Papers citing the target paper potentially delve into leveraging prior information for learning, specifically emphasizing bias in learning methods.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Inductive learning\n",
      "Biasing learning methods\n",
      "Prior concepts utilization\n",
      "Transference bias\n",
      "M-FOCL algorithm\n",
      "Horn clause\n",
      "Relational learning\n",
      "Multiple concepts\n",
      "Empirical evaluation\n",
      "Noise-free data\n",
      "Noisy data\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Utilizing Prior Concepts for Learning\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 56115\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" focuses on case-based learning amidst irrelevant features and introduces the Oblivion algorithm for efficient feature identification, particularly in scenarios with interacting features like parity concepts. It discusses experimental findings and future research directions related to irrelevant features. Unfortunately, details about the target paper, \"Improving Tactical Plans with Genetic Algorithms,\" are not provided, so it's challenging to ascertain its specific relevance to the source paper.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Genetic algorithms\n",
      "Tactical plans\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Improving Tactical Plans with Genetic Algorithms\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 72908\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning with irrelevant features, emphasizing feature identification even in scenarios involving interacting features like parity concepts. It discusses experimental outcomes and future research directions in handling irrelevant features. The target paper, \"Applications of a logical discovery engine,\" introduces the clausal discovery engine claudien, highlighting its capabilities in discovering data regularities through inductive logic programming for various applications like learning integrity constraints, functional dependencies, sequence properties, mixed quantitative and qualitative laws, reverse engineering, and classification rules. The citation relationship indicates a paper exploring the applications of a logical discovery engine within the realm of rule learning.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Claudien\n",
      "Logical discovery engine\n",
      "Regularities in data\n",
      "Inductive logic programming\n",
      "Integrity constraints\n",
      "Functional dependencies\n",
      "Sequences\n",
      "Mixed quantitative and qualitative laws\n",
      "Reverse engineering\n",
      "Classification rules\n",
      "Rule learning\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Applications of a logical discovery engine\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 83461\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for case-based learning amidst irrelevant features, emphasizing feature identification, even in scenarios involving interacting features such as parity concepts. It presents experimental outcomes and future research directions regarding irrelevant features. The target paper, \"Dlab: A Declarative Language Bias Formalism,\" details Dlab's functionalities in defining and traversing finite subspaces of first-order clausal logic within inductive learning systems, focusing on syntactical definition, Prolog implementation, and applications in concept learning and knowledge discovery. The citation relationship indicates a theoretical evaluation and selection of biases in machine learning, potentially connecting the declarative language bias presented in Dlab to broader theoretical considerations in machine learning biases.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Dlab\n",
      "Declarative language bias\n",
      "Inductive learning systems\n",
      "First-order clausal logic\n",
      "Syntactical definition\n",
      "Prolog implementation\n",
      "Concept learning\n",
      "Knowledge discovery\n",
      "Rule learning\n",
      "Machine learning biases\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Dlab: A Declarative Language Bias Formalism\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 17811\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for efficient feature identification in case-based learning with irrelevant features. It explores experimental outcomes and future research directions concerning irrelevant features. The target paper, \"#1 Robust Feature Selection Algorithms,\" emphasizes the brittleness of traditional feature selection methods and proposes using genetic algorithms to enhance robustness without compromising computational efficiency. The citation relationship involves a paper on robust feature selection algorithms referencing the target paper's approach using genetic algorithms.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Feature selection\n",
      "Genetic algorithms\n",
      "Robustness\n",
      "Computational efficiency\n",
      "Pattern recognition\n",
      "Adaptive control\n",
      "Machine learning\n",
      "Brittleness\n",
      "Reference to the target paper: Genetic algorithms in feature selection algorithms\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: #1 Robust Feature Selection Algorithms\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "10169 37483\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for efficient feature identification in case-based learning amidst irrelevant features, emphasizing scenarios with interacting features like parity concepts. It reports experimental outcomes and future research directions regarding irrelevant features. The target paper, \"Learning Approximate Control Rules Of High Utility,\" tackles the utility problem in explanation-based learning, proposing techniques to enhance rule utility through AxA-EBL, a fusion of explanation-based learning and inductive learning, demonstrating significant performance improvements over standard EBL in various domains. Papers citing the target paper might explore methods for improving rule utility in explanation-based learning.\n",
      "\n",
      "Keywords for the source paper:\n",
      "\n",
      "Case-based learning\n",
      "Irrelevant features\n",
      "Oblivion algorithm\n",
      "Feature identification\n",
      "Parity concepts\n",
      "Experimental results\n",
      "Future research implications\n",
      "Keywords for the target paper:\n",
      "\n",
      "Explanation-based learning\n",
      "Rule utility\n",
      "Inductive learning\n",
      "Approximate control rules\n",
      "AxA-EBL algorithm\n",
      "Utility problem\n",
      "Performance improvement\n",
      "Domains\n",
      "Improvement in explanation-based learning\n",
      "Enhanced rule utility\n",
      "Is there an existing citation relationship between \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\" and \"Title: Learning Approximate Control Rules Of High Utility\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "src_title = sample[sample.pid == src_id]['title'].values[0]\n",
    "\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    if sample.loc[i, 'pid'] == src_id:\n",
    "        continue\n",
    "\n",
    "    tar_pid, tar_title = sample.loc[i, 'pid'], sample.loc[i, 'title']\n",
    "\n",
    "    h1 = sample.loc[i, 'h1']\n",
    "    print(src_id, tar_pid)\n",
    "\n",
    "\n",
    "    prediction_prompt = f\"\"\"\n",
    "given information of a source paper and a target paper shown as follow:\n",
    "{h1}\n",
    "Is there an existing citation relationship between \"{src_title}\" and \"{tar_title}\"\n",
    "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
    "answer:\n",
    "\n",
    "\"\"\"\n",
    "    print(prediction_prompt)\n",
    "    print('=========================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7838d3e8c8aafe99a49219d607d1f980c3b3b376b8b5bfa134f72b2f876f82e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
