{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pair representations $h_v^{(0)}$  赋值子图中每个节点和源节点信息\n",
    "2. Message $M_v^{(1)}$: {$h_v^{(0)}$, 所有指向v的节点x的$h_x$和(x, v)总结后的信息}\n",
    "3. 总结所有Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample = pd.read_csv('sample.csv')\n",
    "cite = pd.read_csv('sample_cite.csv')\n",
    "\n",
    "# 第一步\n",
    "src = sample[sample.pid == 144330]\n",
    "# tar = sample[sample.pid == 63486]\n",
    "v_df = sample[sample.pid != src.pid.values[0]].reset_index(drop=True)\n",
    "\n",
    "h_v = pd.DataFrame({\n",
    "    'src_pid': [src.pid.values[0]] * len(v_df),\n",
    "    'src_title': [src.title.values[0]] * len(v_df),\n",
    "    'src_abs': [src['abs'].values[0]] * len(v_df),\n",
    "    'src_label': [src.label.values[0]] * len(v_df),\n",
    "    'v_pid': v_df.pid,\n",
    "    'v_title': v_df.title,\n",
    "    'v_abs': v_df['abs'],\n",
    "    'v_label': v_df.label\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>title</th>\n",
       "      <th>abs</th>\n",
       "      <th>label</th>\n",
       "      <th>h0_10169</th>\n",
       "      <th>h1_10169</th>\n",
       "      <th>h0_144330</th>\n",
       "      <th>h1_144330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63486</td>\n",
       "      <td>Title: Evaluation and Selection of Biases in M...</td>\n",
       "      <td>Abstract: In this introduction, we define the ...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>\\nThe source paper, \"Utilizing Prior Concepts ...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2440</td>\n",
       "      <td>Title: Quinlan, 1990 J.R. Quinlan. Learning lo...</td>\n",
       "      <td>Abstract: We describe a ranked-model semantics...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3231</td>\n",
       "      <td>Title: Irrelevant Features and the Subset Sele...</td>\n",
       "      <td>Abstract: We address the problem of finding a ...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10169</td>\n",
       "      <td>Title: Learning Boolean Concepts in the Presen...</td>\n",
       "      <td>Abstract: In this paper, we address the proble...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>954315</td>\n",
       "      <td>Title: Inductive Database Design</td>\n",
       "      <td>Abstract: When designing a (deductive) databas...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>\\nThe source paper, \"Utilizing Prior Concepts ...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144330</td>\n",
       "      <td>Title: Utilizing Prior Concepts for Learning</td>\n",
       "      <td>Abstract: The inductive learning problem consi...</td>\n",
       "      <td>Theory</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56115</td>\n",
       "      <td>Title: Improving Tactical Plans with Genetic A...</td>\n",
       "      <td>Abstract:</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts ...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>It seems there's no abstract provided for the ...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72908</td>\n",
       "      <td>Title: Applications of a logical discovery engine</td>\n",
       "      <td>Abstract: The clausal discovery engine claudie...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>83461</td>\n",
       "      <td>Title: Dlab: A Declarative Language Bias Forma...</td>\n",
       "      <td>Abstract: We describe the principles and funct...</td>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17811</td>\n",
       "      <td>Title: #1 Robust Feature Selection Algorithms</td>\n",
       "      <td>Abstract: Selecting a set of features which is...</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37483</td>\n",
       "      <td>Title: Learning Approximate Control Rules Of H...</td>\n",
       "      <td>Abstract: One of the difficult problems in the...</td>\n",
       "      <td>Case_Based</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Learning Boolean Concepts i...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "      <td>The source paper, \"Utilizing Prior Concepts fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pid                                              title  \\\n",
       "0    63486  Title: Evaluation and Selection of Biases in M...   \n",
       "1     2440  Title: Quinlan, 1990 J.R. Quinlan. Learning lo...   \n",
       "2     3231  Title: Irrelevant Features and the Subset Sele...   \n",
       "3    10169  Title: Learning Boolean Concepts in the Presen...   \n",
       "4   954315                   Title: Inductive Database Design   \n",
       "5   144330       Title: Utilizing Prior Concepts for Learning   \n",
       "6    56115  Title: Improving Tactical Plans with Genetic A...   \n",
       "7    72908  Title: Applications of a logical discovery engine   \n",
       "8    83461  Title: Dlab: A Declarative Language Bias Forma...   \n",
       "9    17811      Title: #1 Robust Feature Selection Algorithms   \n",
       "10   37483  Title: Learning Approximate Control Rules Of H...   \n",
       "\n",
       "                                                  abs               label  \\\n",
       "0   Abstract: In this introduction, we define the ...              Theory   \n",
       "1   Abstract: We describe a ranked-model semantics...       Rule_Learning   \n",
       "2   Abstract: We address the problem of finding a ...              Theory   \n",
       "3   Abstract: In this paper, we address the proble...              Theory   \n",
       "4   Abstract: When designing a (deductive) databas...       Rule_Learning   \n",
       "5   Abstract: The inductive learning problem consi...              Theory   \n",
       "6                                           Abstract:  Genetic_Algorithms   \n",
       "7   Abstract: The clausal discovery engine claudie...       Rule_Learning   \n",
       "8   Abstract: We describe the principles and funct...       Rule_Learning   \n",
       "9   Abstract: Selecting a set of features which is...  Genetic_Algorithms   \n",
       "10  Abstract: One of the difficult problems in the...          Case_Based   \n",
       "\n",
       "                                             h0_10169  \\\n",
       "0   The source paper, \"Learning Boolean Concepts i...   \n",
       "1   The source paper, \"Learning Boolean Concepts i...   \n",
       "2   The source paper, \"Learning Boolean Concepts i...   \n",
       "3                                                 NaN   \n",
       "4   The source paper, \"Learning Boolean Concepts i...   \n",
       "5   The source paper, \"Learning Boolean Concepts i...   \n",
       "6    The source paper, \"Learning Boolean Concepts ...   \n",
       "7   The source paper, \"Learning Boolean Concepts i...   \n",
       "8   The source paper, \"Learning Boolean Concepts i...   \n",
       "9   The source paper, \"Learning Boolean Concepts i...   \n",
       "10  The source paper, \"Learning Boolean Concepts i...   \n",
       "\n",
       "                                             h1_10169  \\\n",
       "0   The source paper, \"Learning Boolean Concepts i...   \n",
       "1   The source paper, \"Learning Boolean Concepts i...   \n",
       "2   The source paper, \"Learning Boolean Concepts i...   \n",
       "3                                                 NaN   \n",
       "4   The source paper, \"Learning Boolean Concepts i...   \n",
       "5   The source paper, \"Learning Boolean Concepts i...   \n",
       "6   The source paper, \"Learning Boolean Concepts i...   \n",
       "7   The source paper, \"Learning Boolean Concepts i...   \n",
       "8   The source paper, \"Learning Boolean Concepts i...   \n",
       "9   The source paper, \"Learning Boolean Concepts i...   \n",
       "10  The source paper, \"Learning Boolean Concepts i...   \n",
       "\n",
       "                                            h0_144330  \\\n",
       "0   \\nThe source paper, \"Utilizing Prior Concepts ...   \n",
       "1   The source paper, \"Utilizing Prior Concepts fo...   \n",
       "2   The source paper, \"Utilizing Prior Concepts fo...   \n",
       "3   The source paper, \"Utilizing Prior Concepts fo...   \n",
       "4   \\nThe source paper, \"Utilizing Prior Concepts ...   \n",
       "5                                                 NaN   \n",
       "6   It seems there's no abstract provided for the ...   \n",
       "7   The source paper, \"Utilizing Prior Concepts fo...   \n",
       "8   The source paper, \"Utilizing Prior Concepts fo...   \n",
       "9   The source paper, \"Utilizing Prior Concepts fo...   \n",
       "10  The source paper, \"Utilizing Prior Concepts fo...   \n",
       "\n",
       "                                            h1_144330  \n",
       "0   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "1   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "2   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "3   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "4   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "5                                                 NaN  \n",
       "6   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "7   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "8   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "9   The source paper, \"Utilizing Prior Concepts fo...  \n",
       "10  The source paper, \"Utilizing Prior Concepts fo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63486\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Evaluation and Selection of Biases in Machine Learning\n",
      "abstract:Abstract: In this introduction, we define the term bias as it is used in machine learning systems. We motivate the importance of automated methods for evaluating and selecting biases using a framework of bias selection as search in bias and meta-bias spaces. Recent research in the field of machine learning bias is summarized.\n",
      "label:Theory\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "2440\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\n",
      "abstract:Abstract: We describe a ranked-model semantics for if-then rules admitting exceptions, which provides a coherent framework for many facets of evidential and causal reasoning. Rule priorities are automatically extracted form the knowledge base to facilitate the construction and retraction of plausible beliefs. To represent causation, the formalism incorporates the principle of Markov shielding which imposes a stratified set of independence constraints on rankings of interpretations. We show how this formalism resolves some classical problems associated with specificity, prediction and abduction, and how it offers a natural way of unifying belief revision, belief update, and reasoning about actions.\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "3231\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Irrelevant Features and the Subset Selection Problem\n",
      "abstract:Abstract: We address the problem of finding a subset of features that allows a supervised induction algorithm to induce small high-accuracy concepts. We examine notions of relevance and irrelevance, and show that the definitions used in the machine learning literature do not adequately partition the features into useful categories of relevance. We present definitions for irrelevance and for two degrees of relevance. These definitions improve our understanding of the behavior of previous subset selection algorithms, and help define the subset of features that should be sought. The features selected should depend not only on the features and the target concept, but also on the induction algorithm. We describe a method for feature subset selection using cross-validation that is applicable to any induction algorithm, and discuss experiments conducted with ID3 and C4.5 on artificial and real datasets.\n",
      "label:Theory\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "10169\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\n",
      "abstract:Abstract: In this paper, we address the problem of case-based learning in the presence of irrelevant features. We review previous work on attribute selection and present a new algorithm, Oblivion, that carries out greedy pruning of oblivious decision trees, which effectively store a set of abstract cases in memory. We hypothesize that this approach will efficiently identify relevant features even when they interact, as in parity concepts. We report experimental results on artificial domains that support this hypothesis, and experiments with natural domains that show improvement in some cases but not others. In closing, we discuss the implications of our experiments, consider additional work on irrelevant features, and outline some directions for future research.\n",
      "label:Theory\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "954315\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Inductive Database Design\n",
      "abstract:Abstract: When designing a (deductive) database, the designer has to decide for each predicate (or relation) whether it should be defined extensionally or intensionally, and what the definition should look like. An intelligent system is presented to assist the designer in this task. It starts from an example database in which all predicates are defined extensionally. It then tries to compact the database by transforming extensionally defined predicates into intensionally defined ones. The intelligent system employs techniques from the area of inductive logic programming.\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "56115\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Improving Tactical Plans with Genetic Algorithms\n",
      "abstract:Abstract:\n",
      "label:Genetic_Algorithms\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "72908\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Applications of a logical discovery engine\n",
      "abstract:Abstract: The clausal discovery engine claudien is presented. claudien discovers regularities in data and is a representative of the inductive logic programming paradigm. As such, it represents data and regularities by means of first order clausal theories. Because the search space of clausal theories is larger than that of attribute value representation, claudien also accepts as input a declarative specification of the language bias, which determines the set of syntactically well-formed regularities. Whereas other papers on claudien focuss on the semantics or logical problem specification of claudien, on the discovery algorithm, or the PAC-learning aspects, this paper wants to illustrate the power of the resulting technique. In order to achieve this aim, we show how claudien can be used to learn 1) integrity constraints in databases, 2) functional dependencies and determinations, 3) properties of sequences, 4) mixed quantitative and qualitative laws, 5) reverse engineering, and 6) classification rules.\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "83461\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Dlab: A Declarative Language Bias Formalism\n",
      "abstract:Abstract: We describe the principles and functionalities of Dlab (Declarative LAnguage Bias). Dlab can be used in inductive learning systems to define syntactically and traverse efficiently finite subspaces of first order clausal logic, be it a set of propositional formulae, association rules, Horn clauses, or full clauses. A Prolog implementation of Dlab is available by ftp access. Keywords: declarative language bias, concept learning, knowledge dis covery\n",
      "label:Rule_Learning\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "17811\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: #1 Robust Feature Selection Algorithms\n",
      "abstract:Abstract: Selecting a set of features which is optimal for a given task is a problem which plays an important role in a wide variety of contexts including pattern recognition, adaptive control, and machine learning. Our experience with traditional feature selection algorithms in the domain of machine learning lead to an appreciation for their computational efficiency and a concern for their brittleness. This paper describes an alternate approach to feature selection which uses genetic algorithms as the primary search component. Results are presented which suggest that genetic algorithms can be used to increase the robustness of feature selection algorithms without a significant decrease in computational efficiency.\n",
      "label:Genetic_Algorithms\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n",
      "37483\n",
      "\n",
      "Given information of a source paper and a target paper shown as follow:\n",
      "source paper:\n",
      "title:Title: Utilizing Prior Concepts for Learning\n",
      "abstract:Abstract: The inductive learning problem consists of learning a concept given examples and non-examples of the concept. To perform this learning task, inductive learning algorithms bias their learning method. Here we discuss biasing the learning method to use previously learned concepts from the same domain. These learned concepts highlight useful information for other concepts in the domain. We describe a transference bias and present M-FOCL, a Horn clause relational learning algorithm, that utilizes this bias to learn multiple concepts. We provide preliminary empirical evaluation to show the effects of biasing previous information on noise-free and noisy data.\n",
      "label:Theory\n",
      "target paper:\n",
      "title:Title: Learning Approximate Control Rules Of High Utility\n",
      "abstract:Abstract: One of the difficult problems in the area of explanation based learning is the utility problem; learning too many rules of low utility can lead to swamping, or degradation of performance. This paper introduces two new techniques for improving the utility of learned rules. The first technique is to combine EBL with inductive learning techniques to learn a better set of control rules; the second technique is to use these inductive techniques to learn approximate control rules. The two techniques are synthesized in an algorithm called approximating abductive explanation based learning (AxA-EBL). AxA-EBL is shown to improve substantially over standard EBL in several domains.\n",
      "label:Case_Based\n",
      "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Indicator\n",
    "# h0\n",
    "\n",
    "for i in range(len(h_v)):\n",
    "\n",
    "    src_title, src_abs, src_label = h_v.loc[i, 'src_title'], h_v.loc[i, 'src_abs'], h_v.loc[i, 'src_label']\n",
    "    tar_pid, tar_title, tar_abs, tar_label = h_v.loc[i, 'v_pid'], h_v.loc[i, 'v_title'], h_v.loc[i, 'v_abs'], h_v.loc[i, 'v_label']\n",
    "\n",
    "    # if tar['pid'].values[0] == tar_pid:\n",
    "    #     continue\n",
    "    \n",
    "    print(tar_pid)\n",
    "\n",
    "    Indicator_prompt = f\"\"\"\n",
    "Given information of a source paper and a target paper shown as follow:\n",
    "source paper:\n",
    "title:{src_title}\n",
    "abstract:{src_abs}\n",
    "label:{src_label}\n",
    "target paper:\n",
    "title:{tar_title}\n",
    "abstract:{tar_abs}\n",
    "label:{tar_label}\n",
    "please summarize information of these two papers in no more than three sentences, and then generate some keywords of this information.\n",
    "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
    "\"\"\"\n",
    "\n",
    "    print(Indicator_prompt)\n",
    "    print('======================================================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440 72908\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" focuses on leveraging previously learned concepts in inductive learning algorithms, introducing a transference bias via the M-FOCL algorithm for multi-concept learning and presenting empirical evaluations on its impact on noise-free and noisy data. The target paper, \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations,\" introduces a ranked-model semantics for if-then rules with exceptions, emphasizing causal and evidential reasoning, Markov shielding for causation representation, and the resolution of classical issues in prediction, abduction, and belief revision.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Multi-concept Learning, Empirical Evaluation\n",
      "Target Paper: Ranked-Model Semantics, If-Then Rules, Causal Reasoning, Evidential Reasoning, Markov Shielding, Prediction, Abduction, Belief Revision\n",
      "\n",
      "the paper which target paper cites: title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In, label:Rule_Learning cites title:Title: Applications of a logical discovery engine, label:Rule_Learning.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "3231 63486\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" delves into leveraging previously learned concepts in inductive learning through a transference bias using the M-FOCL algorithm, demonstrating its impact via empirical evaluations on both noise-free and noisy data. The target paper, \"Irrelevant Features and the Subset Selection Problem,\" focuses on defining relevance and irrelevance in feature subsets for supervised induction algorithms, proposing improved definitions and a method for feature subset selection via cross-validation applicable to various induction algorithms like ID3 and C4.5.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Feature Subset Selection, Relevance, Irrelevance, Supervised Induction Algorithms, Definitions, Cross-Validation, ID3, C4.5\n",
      "\n",
      "the paper which target paper cites: title:Title: Irrelevant Features and the Subset Selection Problem, label:Theory cites title:Title: Evaluation and Selection of Biases in Machine Learning, label:Theory.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "10169 3231\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously learned concepts in inductive learning through a transference bias, demonstrated via the M-FOCL algorithm's application and empirical evaluations on noise-free and noisy data. The target paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" addresses case-based learning amidst irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees to identify relevant features, especially in cases like parity concepts, supported by experiments in artificial and natural domains.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Case-Based Learning, Irrelevant Features, Oblivion Algorithm, Greedy Pruning, Decision Trees, Relevant Features Identification, Parity Concepts, Experimental Results\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the paper which target paper cites: title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features, label:Theory cites title:Title: Irrelevant Features and the Subset Selection Problem, label:Theory.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "10169 63486\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously learned concepts in inductive learning through a transference bias, demonstrated via the M-FOCL algorithm's application and empirical evaluations on noise-free and noisy data. The target paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" addresses case-based learning amidst irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees to identify relevant features, especially in cases like parity concepts, supported by experiments in artificial and natural domains.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Case-Based Learning, Irrelevant Features, Oblivion Algorithm, Greedy Pruning, Decision Trees, Relevant Features Identification, Parity Concepts, Experimental Results\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the paper which target paper cites: title:Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features, label:Theory cites title:Title: Evaluation and Selection of Biases in Machine Learning, label:Theory.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "17811 63486\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" explores the application of previously learned concepts through a transference bias in inductive learning, showcasing the M-FOCL algorithm's utilization and its impact through preliminary empirical evaluation on noise-free and noisy data. In contrast, the target paper, \"#1 Robust Feature Selection Algorithms,\" discusses robust feature selection using genetic algorithms, highlighting their role in enhancing feature selection algorithms' robustness without compromising computational efficiency in machine learning contexts.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Feature Selection, Genetic Algorithms, Robustness, Computational Efficiency, Pattern Recognition, Adaptive Control, Machine Learning\n",
      "\n",
      "the paper which target paper cites: title:Title: #1 Robust Feature Selection Algorithms, label:Genetic_Algorithms cites title:Title: Evaluation and Selection of Biases in Machine Learning, label:Theory.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "37483 2440\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" delves into leveraging prior concepts via a transference bias in inductive learning, employing the M-FOCL algorithm and showcasing its effects through empirical evaluations on noise-free and noisy data. In contrast, the target paper, \"Learning Approximate Control Rules Of High Utility,\" addresses the utility problem in explanation-based learning, introducing techniques that combine EBL with inductive learning for improved control rule sets, culminating in the AxA-EBL algorithm enhancing rule learning by integrating approximate control rules.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Explanation-Based Learning, Utility Problem, Inductive Learning Techniques, Control Rules, Approximate Control Rules, AxA-EBL Algorithm, Rule Learning\n",
      "\n",
      "the paper which target paper cites: title:Title: Learning Approximate Control Rules Of High Utility, label:Case_Based cites title:Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In, label:Rule_Learning.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "56115 63486\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: It seems there's no abstract provided for the \"Improving Tactical Plans with Genetic Algorithms\" paper, which makes it challenging to summarize its content. However, based on the information available, the source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously learned concepts in inductive learning using a transference bias via the M-FOCL algorithm, evaluated on noise-free and noisy data. Keywords for this information might include: Inductive Learning, Transference Bias, M-FOCL Algorithm, Multiple Concepts, Empirical Evaluation. Unfortunately, without details from the target paper's abstract or content, it's challenging to provide keywords or a summary for it.\n",
      "\n",
      "the paper which target paper cites: title:Title: Improving Tactical Plans with Genetic Algorithms, label:Genetic_Algorithms cites title:Title: Evaluation and Selection of Biases in Machine Learning, label:Theory.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "63486 83461\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: \n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" discusses using previously learned concepts to bias the learning method in inductive learning algorithms, showcasing the application of transference bias in the M-FOCL algorithm to learn multiple concepts. It presents empirical evaluation on the impact of leveraging prior information on both noise-free and noisy data. The target paper, \"Evaluation and Selection of Biases in Machine Learning,\" introduces the concept of bias in ML systems, emphasizing the need for automated methods to evaluate and select biases, summarizing recent research in this area.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Utilizing Prior Concepts, Inductive Learning, Transference Bias, M-FOCL Algorithm, Multiple Concepts, Empirical Evaluation\n",
      "Target Paper: Bias in Machine Learning, Automated Bias Evaluation, Bias Selection, Meta-bias Spaces, Recent Research\n",
      "\n",
      "the paper which target paper cites: title:Title: Evaluation and Selection of Biases in Machine Learning, label:Theory cites title:Title: Dlab: A Declarative Language Bias Formalism, label:Rule_Learning.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "72908 954315\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" discusses the utilization of previously learned concepts via a transference bias in inductive learning, employing the M-FOCL algorithm and evaluating its impact on both noise-free and noisy data. In contrast, the target paper, \"Applications of a logical discovery engine,\" introduces the clausal discovery engine claudien in the context of inductive logic programming, showcasing its abilities in discovering regularities in data, such as integrity constraints, functional dependencies, sequences, mixed quantitative and qualitative laws, reverse engineering, and classification rules.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Claudien, Inductive Logic Programming, Regularity Discovery, Data Representation, Language Bias, Integrity Constraints, Functional Dependencies, Reverse Engineering, Classification Rules\n",
      "\n",
      "the paper which target paper cites: title:Title: Applications of a logical discovery engine, label:Rule_Learning cites title:Title: Inductive Database Design, label:Rule_Learning.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n",
      "83461 954315\n",
      "\n",
      "Given the source and target papers, and information about the paper cited by target paper:\n",
      "information of source and target papers: The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously learned concepts via a transference bias in inductive learning, using the M-FOCL algorithm, and showcasing its impact through empirical evaluation on noise-free and noisy data. In contrast, the target paper, \"Dlab: A Declarative Language Bias Formalism,\" introduces Dlab, a framework enabling the definition and efficient traversal of finite subspaces of first-order clausal logic in inductive learning systems, focusing on declarative language bias in concept learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Dlab, Declarative Language Bias, Inductive Learning Systems, First-order Clausal Logic, Concept Learning, Knowledge Discovery\n",
      "\n",
      "the paper which target paper cites: title:Title: Dlab: A Declarative Language Bias Formalism, label:Rule_Learning cites title:Title: Inductive Database Design, label:Rule_Learning.\n",
      "\n",
      "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# message\n",
    "# 遍历cite表所有src_id 不是u的边，获得对应的src_id(x)\n",
    "# 从sample表里获得x的h0，并和cite关系w聚合，得到m\n",
    "# 将m存入cite表\n",
    "\n",
    "for i in range(len(cite)):\n",
    "    src_id, tar_id = cite.loc[i, 'src_id'], cite.loc[i, 'tar_id']\n",
    "    \n",
    "    # 隐去所有以src_id为源的边\n",
    "    if src_id == src.pid.values[0]:\n",
    "        # print(src_id, tar_id)\n",
    "        continue\n",
    "    \n",
    "    src_title, src_abs, src_label = sample[sample.pid == src_id].title.values[0], sample[sample.pid == src_id]['abs'].values[0], sample[sample.pid == src_id].label.values[0]\n",
    "    tar_title, tar_abs, tar_label = sample[sample.pid == tar_id].title.values[0], sample[sample.pid == tar_id]['abs'].values[0], sample[sample.pid == tar_id].label.values[0]\n",
    "    \n",
    "    # hx\n",
    "    hx = sample[sample.pid == src_id][f'h0_{src.pid.values[0]}'].values[0]\n",
    "\n",
    "    w_prompt = f\"\"\"title:{src_title}, label:{src_label} cites title:{tar_title}, label:{tar_label}.\"\"\"\n",
    "\n",
    "    message_prompt = f\"\"\"\n",
    "Given the source and target papers, and information about the paper cited by target paper:\n",
    "information of source and target papers: {hx}\n",
    "\n",
    "the paper which target paper cites: {w_prompt}\n",
    "\n",
    "please summarize information of source and target papers and the citation relationship in no more than three sentences, and then generate some keywords of this information.\n",
    "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
    "\"\"\"\n",
    "\n",
    "    print(src_id, tar_id)\n",
    "    \n",
    "    print(message_prompt)\n",
    "\n",
    "    print('================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63486\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" discusses using previously learned concepts to bias the learning method in inductive learning algorithms, showcasing the application of transference bias in the M-FOCL algorithm to learn multiple concepts. It presents empirical evaluation on the impact of leveraging prior information on both noise-free and noisy data. The target paper, \"Evaluation and Selection of Biases in Machine Learning,\" introduces the concept of bias in ML systems, emphasizing the need for automated methods to evaluate and select biases, summarizing recent research in this area.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Utilizing Prior Concepts, Inductive Learning, Transference Bias, M-FOCL Algorithm, Multiple Concepts, Empirical Evaluation\n",
      "Target Paper: Bias in Machine Learning, Automated Bias Evaluation, Bias Selection, Meta-bias Spaces, Recent Research\n",
      "\n",
      "\n",
      "the information of paper which cites the target paper and their relation of the source paper shown as follow:\n",
      "\n",
      "1. [\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge through a transference bias via the M-FOCL algorithm, evaluating its impact on noisy and noise-free data. The target paper, \"Irrelevant Features and the Subset Selection Problem,\" focuses on defining relevance and irrelevance in feature subsets for supervised induction, proposing a cross-validation-based method for subset selection applicable to algorithms like ID3 and C4.5. The target paper cites \"Evaluation and Selection of Biases in Machine Learning\" in the domain of theoretical considerations related to bias assessment in machine learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Feature Subset Selection, Relevance, Irrelevance, Supervised Induction Algorithms, Definitions, Cross-Validation, ID3, C4.5, Bias Assessment, Theoretical Considerations]\n",
      "\n",
      "2. [The source paper, \"Utilizing Prior Concepts for Learning,\" explores using prior knowledge in inductive learning through a transference bias and empirical assessments on noisy and noise-free data via the M-FOCL algorithm. The target paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" introduces the Oblivion algorithm for decision tree pruning amidst irrelevant features in case-based learning, especially regarding parity concepts, supported by experiments. It cites \"Evaluation and Selection of Biases in Machine Learning\" in the realm of theoretical considerations on bias assessment in machine learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Case-Based Learning, Irrelevant Features, Oblivion Algorithm, Greedy Pruning, Decision Trees, Relevant Features Identification, Parity Concepts, Experimental Results, Bias Assessment, Theoretical Considerations]\n",
      "\n",
      "3. [The source paper, \"Utilizing Prior Concepts for Learning,\" investigates leveraging prior knowledge via a transference bias in inductive learning, showcasing the M-FOCL algorithm and its initial impact through empirical evaluations on noisy and noise-free data. Conversely, the target paper, \"#1 Robust Feature Selection Algorithms,\" focuses on robust feature selection using genetic algorithms, emphasizing their role in enhancing selection methods without sacrificing computational efficiency in machine learning. It cites \"Evaluation and Selection of Biases in Machine Learning\" within theoretical considerations about bias assessment in machine learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Feature Selection, Genetic Algorithms, Robustness, Computational Efficiency, Pattern Recognition, Adaptive Control, Machine Learning, Bias Assessment, Theoretical Considerations]\n",
      "\n",
      "4. [The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge in inductive learning through a transference bias using the M-FOCL algorithm and empirical evaluations on noise-free and noisy data. Unfortunately, without details from the target paper, it's challenging to provide a summary or keywords for its content. However, the target paper, \"Improving Tactical Plans with Genetic Algorithms,\" cites \"Evaluation and Selection of Biases in Machine Learning\" within the domain of theoretical considerations related to bias assessment in machine learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Multiple Concepts, Empirical Evaluation\n",
      "Target Paper: Not enough information available to provide specific keywords or summary]\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "2440\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" focuses on leveraging previously learned concepts in inductive learning algorithms, introducing a transference bias via the M-FOCL algorithm for multi-concept learning and presenting empirical evaluations on its impact on noise-free and noisy data. The target paper, \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations,\" introduces a ranked-model semantics for if-then rules with exceptions, emphasizing causal and evidential reasoning, Markov shielding for causation representation, and the resolution of classical issues in prediction, abduction, and belief revision.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Multi-concept Learning, Empirical Evaluation\n",
      "Target Paper: Ranked-Model Semantics, If-Then Rules, Causal Reasoning, Evidential Reasoning, Markov Shielding, Prediction, Abduction, Belief Revision\n",
      "\n",
      "\n",
      "the information of paper which cites the target paper and their relation of the source paper shown as follow:\n",
      "\n",
      "1. [The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge with a transference bias in inductive learning, using the M-FOCL algorithm and empirical evaluations on noisy and noise-free data. Conversely, the target paper, \"Learning Approximate Control Rules Of High Utility,\" addresses the utility problem in explanation-based learning, merging EBL with inductive techniques to enhance control rule sets via the AxA-EBL algorithm. It cites \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations\" within the domain of rule learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Explanation-Based Learning, Utility Problem, Inductive Learning Techniques, Control Rules, Approximate Control Rules, AxA-EBL Algorithm, Rule Learning, Rule Revision]\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "3231\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" delves into leveraging previously learned concepts in inductive learning through a transference bias using the M-FOCL algorithm, demonstrating its impact via empirical evaluations on both noise-free and noisy data. The target paper, \"Irrelevant Features and the Subset Selection Problem,\" focuses on defining relevance and irrelevance in feature subsets for supervised induction algorithms, proposing improved definitions and a method for feature subset selection via cross-validation applicable to various induction algorithms like ID3 and C4.5.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Feature Subset Selection, Relevance, Irrelevance, Supervised Induction Algorithms, Definitions, Cross-Validation, ID3, C4.5\n",
      "\n",
      "\n",
      "the information of paper which cites the target paper and their relation of the source paper shown as follow:\n",
      "\n",
      "1. [The source paper, \"Utilizing Prior Concepts for Learning,\" investigates leveraging past knowledge in inductive learning through a transference bias using the M-FOCL algorithm and empirical assessments on noisy and noise-free data. The target paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" focuses on case-based learning in the context of irrelevant features, introducing the Oblivion algorithm for decision tree pruning to identify relevant features, particularly in scenarios like parity concepts. It cites \"Irrelevant Features and the Subset Selection Problem\" in the domain of theoretical considerations related to handling irrelevant features.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Case-Based Learning, Irrelevant Features, Oblivion Algorithm, Greedy Pruning, Decision Trees, Relevant Features Identification, Parity Concepts, Theoretical Considerations]\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "10169\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously learned concepts in inductive learning through a transference bias, demonstrated via the M-FOCL algorithm's application and empirical evaluations on noise-free and noisy data. The target paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" addresses case-based learning amidst irrelevant features, introducing the Oblivion algorithm for greedy pruning of decision trees to identify relevant features, especially in cases like parity concepts, supported by experiments in artificial and natural domains.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Case-Based Learning, Irrelevant Features, Oblivion Algorithm, Greedy Pruning, Decision Trees, Relevant Features Identification, Parity Concepts, Experimental Results\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "954315\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" focuses on employing previously learned concepts through a transference bias in inductive learning via the M-FOCL algorithm, showcasing effects on multiple concepts via empirical evaluation. In contrast, the target paper, \"Inductive Database Design,\" introduces an intelligent system aiding the design of deductive databases by transforming extensionally defined predicates into intensionally defined ones, utilizing techniques from inductive logic programming.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Multiple Concepts\n",
      "Target Paper: Deductive Database Design, Extensional Definitions, Intensional Definitions, Intelligent System, Inductive Logic Programming\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the information of paper which cites the target paper and their relation of the source paper shown as follow:\n",
      "\n",
      "1. [The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously acquired knowledge with a transference bias in inductive learning via the M-FOCL algorithm, assessing its effects on noise-free and noisy data. In contrast, the target paper, \"Applications of a logical discovery engine,\" introduces claudien, a clausal discovery engine in the domain of inductive logic programming, showcasing its capabilities in discovering various regularities in data types like integrity constraints, functional dependencies, and classification rules. The target paper cites \"Inductive Database Design\" within the realm of rule learning related to the design aspects of inductive databases.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Claudien, Inductive Logic Programming, Regularity Discovery, Data Representation, Language Bias, Integrity Constraints, Functional Dependencies, Reverse Engineering, Classification Rules, Rule Learning, Inductive Database Design]\n",
      "\n",
      "2. [The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge through a transference bias in inductive learning using the M-FOCL algorithm and evaluating its effects on noise-free and noisy data. Conversely, the target paper, \"Dlab: A Declarative Language Bias Formalism,\" introduces Dlab, a framework focusing on declarative language bias in first-order clausal logic within inductive learning systems for concept learning. The target paper cites \"Inductive Database Design\" within the domain of rule learning, likely pertaining to aspects of designing databases for inductive systems.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Dlab, Declarative Language Bias, Inductive Learning Systems, First-order Clausal Logic, Concept Learning, Knowledge Discovery, Rule Learning, Inductive Database Design]\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "144330\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "nan\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "56115\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "It seems there's no abstract provided for the \"Improving Tactical Plans with Genetic Algorithms\" paper, which makes it challenging to summarize its content. However, based on the information available, the source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously learned concepts in inductive learning using a transference bias via the M-FOCL algorithm, evaluated on noise-free and noisy data. Keywords for this information might include: Inductive Learning, Transference Bias, M-FOCL Algorithm, Multiple Concepts, Empirical Evaluation. Unfortunately, without details from the target paper's abstract or content, it's challenging to provide keywords or a summary for it.\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "72908\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" discusses the utilization of previously learned concepts via a transference bias in inductive learning, employing the M-FOCL algorithm and evaluating its impact on both noise-free and noisy data. In contrast, the target paper, \"Applications of a logical discovery engine,\" introduces the clausal discovery engine claudien in the context of inductive logic programming, showcasing its abilities in discovering regularities in data, such as integrity constraints, functional dependencies, sequences, mixed quantitative and qualitative laws, reverse engineering, and classification rules.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Claudien, Inductive Logic Programming, Regularity Discovery, Data Representation, Language Bias, Integrity Constraints, Functional Dependencies, Reverse Engineering, Classification Rules\n",
      "\n",
      "\n",
      "the information of paper which cites the target paper and their relation of the source paper shown as follow:\n",
      "\n",
      "1. [\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior concepts in inductive learning via the M-FOCL algorithm for multi-concept learning, assessing its impact on noise-free and noisy data. The target paper, \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations,\" introduces ranked-model semantics for if-then rules, emphasizing causal and evidential reasoning alongside addressing issues in prediction, abduction, and belief revision. The target paper cites \"Applications of a logical discovery engine\" in the realm of rule learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Multi-concept Learning, Empirical Evaluation\n",
      "Target Paper: Ranked-Model Semantics, If-Then Rules, Causal Reasoning, Evidential Reasoning, Prediction, Abduction, Belief Revision, Logical Discovery Engine, Rule Learning]\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "83461\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging previously learned concepts via a transference bias in inductive learning, using the M-FOCL algorithm, and showcasing its impact through empirical evaluation on noise-free and noisy data. In contrast, the target paper, \"Dlab: A Declarative Language Bias Formalism,\" introduces Dlab, a framework enabling the definition and efficient traversal of finite subspaces of first-order clausal logic in inductive learning systems, focusing on declarative language bias in concept learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Dlab, Declarative Language Bias, Inductive Learning Systems, First-order Clausal Logic, Concept Learning, Knowledge Discovery\n",
      "\n",
      "\n",
      "the information of paper which cites the target paper and their relation of the source paper shown as follow:\n",
      "\n",
      "1. [The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge to bias inductive learning via the M-FOCL algorithm, focusing on transference bias and empirical evaluations on noise-free and noisy data. In contrast, the target paper, \"Evaluation and Selection of Biases in Machine Learning,\" addresses the concept of bias in ML systems, emphasizing the need for automated bias evaluation and selection methods, summarizing recent research in this domain. The target paper cites \"Dlab: A Declarative Language Bias Formalism\" within the context of rule learning and formalism related to bias.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Utilizing Prior Concepts, Inductive Learning, Transference Bias, M-FOCL Algorithm, Multiple Concepts, Empirical Evaluation\n",
      "Target Paper: Bias in Machine Learning, Automated Bias Evaluation, Bias Selection, Meta-bias Spaces, Rule Learning, Declarative Language Bias Formalism]\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "17811\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores the application of previously learned concepts through a transference bias in inductive learning, showcasing the M-FOCL algorithm's utilization and its impact through preliminary empirical evaluation on noise-free and noisy data. In contrast, the target paper, \"#1 Robust Feature Selection Algorithms,\" discusses robust feature selection using genetic algorithms, highlighting their role in enhancing feature selection algorithms' robustness without compromising computational efficiency in machine learning contexts.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Feature Selection, Genetic Algorithms, Robustness, Computational Efficiency, Pattern Recognition, Adaptive Control, Machine Learning\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n",
      "37483\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" delves into leveraging prior concepts via a transference bias in inductive learning, employing the M-FOCL algorithm and showcasing its effects through empirical evaluations on noise-free and noisy data. In contrast, the target paper, \"Learning Approximate Control Rules Of High Utility,\" addresses the utility problem in explanation-based learning, introducing techniques that combine EBL with inductive learning for improved control rule sets, culminating in the AxA-EBL algorithm enhancing rule learning by integrating approximate control rules.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Explanation-Based Learning, Utility Problem, Inductive Learning Techniques, Control Rules, Approximate Control Rules, AxA-EBL Algorithm, Rule Learning\n",
      "\n",
      "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
      "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
      "\n",
      "================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个不是源点的sample\n",
    "# 找到所有以该点为终点的边，组合message\n",
    "# \n",
    "\n",
    "src_id = src.pid.values[0]\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    v_id, h0 = sample.loc[i, 'pid'], sample.loc[i, f'h0_{src_id}']\n",
    "    m_list = cite[(cite.tar_id == v_id) & (cite.src_id != src_id)][f'm_{src_id}'].values\n",
    "\n",
    "    # print(v_id, m_list)\n",
    "\n",
    "    agg_prompt = f'''\n",
    "given information of a source paper and a target paper shown as follow:\n",
    "{h0}\n",
    "'''\n",
    "\n",
    "    print(v_id)\n",
    "    if len(m_list) > 0:\n",
    "        agg_prompt = f'''{agg_prompt}\\n\n",
    "the information of paper which cites the target paper and their relation of the source paper shown as follow:\n",
    "'''\n",
    "        for j, m in enumerate(m_list):\n",
    "            agg_prompt = f\"{agg_prompt}\\n{j+1}. [{m}]\\n\"\n",
    "    agg_prompt = f'''{agg_prompt}\n",
    "please summarize information in no more than three sentences, and then generate some keywords of this information.\n",
    "When outputting your answer, when referring to a paper, you should state the title of the paper and indicate whether it is a source paper or a target paper.\n",
    "'''\n",
    "    print(agg_prompt)\n",
    "    print('================================================================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144330 63486\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge through transference bias in inductive learning via the M-FOCL algorithm, assessing its impact on noisy and noise-free data. The target paper, \"Evaluation and Selection of Biases in Machine Learning,\" is cited in various works focusing on theoretical considerations regarding bias assessment in machine learning but lacks specific details in the provided context.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Knowledge, Empirical Evaluation, Noisy Data, Noise-Free Data\n",
      "Target Paper: Bias Assessment, Theoretical Considerations, Citation, Machine Learning\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Evaluation and Selection of Biases in Machine Learning\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 2440\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" investigates leveraging prior knowledge through a transference bias using the M-FOCL algorithm in inductive learning, assessing its impact on noise-free and noisy data. The target paper, \"Learning Approximate Control Rules Of High Utility,\" addresses the utility problem in explanation-based learning by integrating EBL with inductive techniques via the AxA-EBL algorithm, referencing \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations\" within the context of rule learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Knowledge Utilization, Noise-Free Data, Noisy Data\n",
      "Target Paper: Explanation-Based Learning, Utility Problem, AxA-EBL Algorithm, Inductive Learning Techniques, Control Rules, Rule Learning, Rule Revision\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations. Machine Learning, First-order theory revision. In\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 3231\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge in inductive learning via a transference bias with the M-FOCL algorithm, conducting empirical evaluations on noisy and noise-free data. The target paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" focuses on case-based learning and introduces the Oblivion algorithm for decision tree pruning to identify relevant features, specifically in scenarios involving irrelevant features like parity concepts, referencing \"Irrelevant Features and the Subset Selection Problem\" in theoretical considerations concerning handling irrelevant features.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Knowledge Utilization, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Case-Based Learning, Irrelevant Features, Oblivion Algorithm, Decision Tree Pruning, Relevant Features Identification, Parity Concepts, Theoretical Considerations\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Irrelevant Features and the Subset Selection Problem\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 10169\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge through a transference bias in inductive learning, employing the M-FOCL algorithm and conducting empirical evaluations on noisy and noise-free data. The target paper, \"Learning Boolean Concepts in the Presence of Many Irrelevant Features,\" focuses on case-based learning and introduces the Oblivion algorithm, utilizing greedy pruning of decision trees to identify relevant features, particularly in scenarios involving irrelevant features like parity concepts, substantiated by experiments in both artificial and natural domains.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Knowledge Utilization, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Case-Based Learning, Irrelevant Features, Oblivion Algorithm, Greedy Pruning, Decision Trees, Relevant Features Identification, Parity Concepts, Experimental Results\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Learning Boolean Concepts in the Presence of Many Irrelevant Features\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 954315\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" investigates leveraging past knowledge through a transference bias in inductive learning via the M-FOCL algorithm, assessing its impact on noise-free and noisy data. The target papers, \"Applications of a Logical Discovery Engine\" and \"Dlab: A Declarative Language Bias Formalism,\" introduce systems like claudien and Dlab, respectively, focusing on different aspects of inductive logic programming, rule learning, and database design, citing \"Inductive Database Design\" within the domain of rule learning for designing databases in inductive systems.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Knowledge Utilization, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Papers: Claudien, Dlab, Inductive Logic Programming, Rule Learning, Database Design, Declarative Language Bias, First-order Clausal Logic, Reverse Engineering, Knowledge Discovery, Integrity Constraints, Functional Dependencies, Classification Rules\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Inductive Database Design\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 56115\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" investigates leveraging previously learned concepts in inductive learning via a transference bias using the M-FOCL algorithm, assessed through empirical evaluations on noise-free and noisy data. Unfortunately, due to the absence of details from the abstract or content, summarizing the target paper, \"Improving Tactical Plans with Genetic Algorithms,\" is challenging.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Knowledge Utilization, Multiple Concepts, Empirical Evaluation\n",
      "Target Paper: Insufficient information available for keywords or summary\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Improving Tactical Plans with Genetic Algorithms\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 72908\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior concepts using the M-FOCL algorithm in inductive learning for multi-concept learning, evaluated on noise-free and noisy data. The target paper, \"Quinlan, 1990 J.R. Quinlan. Learning logical definitions from relations,\" introduces ranked-model semantics for if-then rules, emphasizing causal and evidential reasoning while addressing prediction, abduction, belief revision, citing \"Applications of a logical discovery engine\" in the context of rule learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Concepts, Multi-concept Learning, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Ranked-Model Semantics, If-Then Rules, Causal Reasoning, Evidential Reasoning, Prediction, Abduction, Belief Revision, Logical Discovery Engine, Rule Learning\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Applications of a logical discovery engine\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 83461\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" explores leveraging prior knowledge with a transference bias using the M-FOCL algorithm in inductive learning, assessed through empirical evaluations on noise-free and noisy data. Conversely, the target paper, \"Evaluation and Selection of Biases in Machine Learning,\" emphasizes automated bias evaluation and selection methods in ML systems, citing \"Dlab: A Declarative Language Bias Formalism\" within the context of rule learning and bias formalism.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Utilizing Prior Concepts, Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Knowledge Utilization, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Bias in Machine Learning, Automated Bias Evaluation, Bias Selection, Rule Learning, Declarative Language Bias Formalism, Meta-bias Spaces\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Dlab: A Declarative Language Bias Formalism\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 17811\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" investigates leveraging prior concepts via a transference bias in inductive learning, utilizing the M-FOCL algorithm and conducting preliminary empirical evaluations on noise-free and noisy data. In contrast, the target paper, \"#1 Robust Feature Selection Algorithms,\" delves into robust feature selection employing genetic algorithms, emphasizing their role in enhancing robustness without compromising computational efficiency in machine learning.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Concepts, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Feature Selection, Genetic Algorithms, Robustness, Computational Efficiency, Pattern Recognition, Adaptive Control, Machine Learning\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: #1 Robust Feature Selection Algorithms\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n",
      "144330 37483\n",
      "\n",
      "given information of a source paper and a target paper shown as follow:\n",
      "The source paper, \"Utilizing Prior Concepts for Learning,\" investigates leveraging prior concepts via a transference bias in inductive learning using the M-FOCL algorithm, demonstrating its impact through empirical evaluations on noise-free and noisy data. In contrast, the target paper, \"Learning Approximate Control Rules Of High Utility,\" tackles the utility problem in explanation-based learning by combining EBL with inductive techniques, introducing the AxA-EBL algorithm to enhance rule learning through approximate control rules integration.\n",
      "\n",
      "Keywords:\n",
      "Source Paper: Inductive Learning, Transference Bias, M-FOCL Algorithm, Prior Concepts, Empirical Evaluation, Noise-Free Data, Noisy Data\n",
      "Target Paper: Explanation-Based Learning, Utility Problem, Inductive Learning Techniques, Control Rules, Approximate Control Rules, AxA-EBL Algorithm, Rule Learning\n",
      "Is there an existing citation relationship between \"Title: Utilizing Prior Concepts for Learning\" and \"Title: Learning Approximate Control Rules Of High Utility\"\n",
      "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
      "answer:\n",
      "\n",
      "\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "src_title = sample[sample.pid == src_id]['title'].values[0]\n",
    "\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    if sample.loc[i, 'pid'] == src_id:\n",
    "        continue\n",
    "\n",
    "    tar_pid, tar_title = sample.loc[i, 'pid'], sample.loc[i, 'title']\n",
    "\n",
    "    h1 = sample.loc[i, f'h1_{src_id}']\n",
    "    print(src_id, tar_pid)\n",
    "\n",
    "\n",
    "    prediction_prompt = f\"\"\"\n",
    "given information of a source paper and a target paper shown as follow:\n",
    "{h1}\n",
    "Is there an existing citation relationship between \"{src_title}\" and \"{tar_title}\"\n",
    "Do not give any reasoning or logic for your answer. Answer Yes if they have cited relationship, otherwise, answer No.\n",
    "answer:\n",
    "\n",
    "\"\"\"\n",
    "    print(prediction_prompt)\n",
    "    print('=========================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7838d3e8c8aafe99a49219d607d1f980c3b3b376b8b5bfa134f72b2f876f82e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
